{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggleFilters(driver, url):\n",
    "    driver.get(url)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    filters_to_hide = ['shorts', 'tv', 'docs', 'unreleased']\n",
    "\n",
    "    for filter_category in filters_to_hide:\n",
    "        hoverOverFilterMenu(driver, wait)\n",
    "        clickOnFilter(wait, filter_category)\n",
    "        time.sleep(1) \n",
    "\n",
    "def clickOnFilter(wait, filter_category):\n",
    "    hide_url = wait.until(EC.element_to_be_clickable((By.XPATH, f\"//li[@data-category='{filter_category}' and @data-type='hide']/a\")))\n",
    "    hide_url.click()\n",
    "\n",
    "def hoverOverFilterMenu(driver, wait):\n",
    "    menu_icon = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'div.smenu > label > span.ir.s.hide-toggle-icon')))\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element(menu_icon).perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractLetterBoxdFilmUrls(driver, url, num_of_pages=3000, checkpoint_interval=100, start_page = 1):\n",
    "    all_movie_urls = []\n",
    "\n",
    "    for page_num in range(start_page, num_of_pages + 1):\n",
    "        movie_urls = getMovieUrls(driver, url, page_num)\n",
    "        random.seed(page_num)\n",
    "        random.shuffle(movie_urls)\n",
    "        all_movie_urls.extend(movie_urls[:3])\n",
    "        \n",
    "        if page_num % checkpoint_interval == 0:\n",
    "            checkpoint_filename = f'urls_checkpoint_{page_num}.csv'\n",
    "            save_to_csv(all_movie_urls, checkpoint_filename)\n",
    "            print(f\"Saved checkpoint at page {page_num} to {checkpoint_filename}\")\n",
    "            all_movie_urls.clear()\n",
    "\n",
    "    driver.quit()\n",
    "    print(\"Scraping completed.\")\n",
    "\n",
    "    return all_movie_urls\n",
    "\n",
    "def getMovieUrls(driver, url, page_num):\n",
    "    driver.get(f\"{url}/page/{page_num}\")\n",
    "    wait = WebDriverWait(driver, 300)\n",
    "    wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"a.frame\")))\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "    movie_urls = [url.get('href') for url in soup.find_all(\"a\", class_=\"frame\")]\n",
    "    return movie_urls\n",
    "\n",
    "def save_to_csv(urls, filename):\n",
    "    df = pd.DataFrame(urls, columns=['URL'])\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at page 2600 to urls_checkpoint_2600.csv\n",
      "Saved checkpoint at page 2700 to urls_checkpoint_2700.csv\n",
      "Saved checkpoint at page 2800 to urls_checkpoint_2800.csv\n",
      "Saved checkpoint at page 2900 to urls_checkpoint_2900.csv\n",
      "Saved checkpoint at page 3000 to urls_checkpoint_3000.csv\n",
      "Scraping completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.page_load_strategy = 'eager'\n",
    "driver = webdriver.Chrome(options=options)\n",
    "url = \"https://letterboxd.com/films/popular\"\n",
    "driver.get(url)\n",
    "toggleFilters(driver, url)\n",
    "extractLetterBoxdFilmUrls(driver, url, 3000, 100, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob('*.csv')\n",
    "\n",
    "dataframes = [pd.read_csv(file) for file in csv_files]\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "merged_df.to_csv('movie_url_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
